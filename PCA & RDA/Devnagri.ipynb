{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "c569cd2e17f62341e0f08a54f9a867c3c0d3a6f67454072d7de41a8b5dff8343"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils import  flatten,post_prob\n",
    "from pca import PCA\n",
    "from rda import RDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Test', 'Train']"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "main_path = '.\\DevanagariHandwrittenCharacterDataset'\n",
    "os.listdir(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(main_path,'Train')\n",
    "test_path = os.path.join(main_path,'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = os.listdir(train_path)\n",
    "test_folder = os.listdir(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_folder_path = list(map(lambda x : os.path.join(train_path,x),train_folder))\n",
    "test_image_folder_path = list(map(lambda x : os.path.join(test_path,x),test_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = []\n",
    "for i in train_image_folder_path:\n",
    "    for j in os.listdir(i):\n",
    "        train_image_path.append(os.path.join(i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = []\n",
    "for i in test_image_folder_path:\n",
    "    for j in os.listdir(i):\n",
    "        test_image_path.append(os.path.join(i,j))"
   ]
  },
  {
   "source": [
    "Flattening the images so as to convert them for proper input size for our model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.concatenate(flatten(train_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.concatenate(flatten(test_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = np.arange(0,len(train_image_folder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = []\n",
    "class_labels.extend(map(lambda x : x*np.ones((1700,1)),unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = np.concatenate(class_labels)"
   ]
  },
  {
   "source": [
    "## Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['labels'] = class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.concatenate(list(map(lambda x : x * np.ones((300,1)),unique_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label'] = test_labels"
   ]
  },
  {
   "source": [
    "## Applying PCA on our dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**PCA** : Principal component analysis (PCA) is a technique for reducing the dimensionality of such datasets, increasing interpretability but at the same time minimizing information loss. It does so by creating new uncorrelated variables that successively maximize variance.\n",
    "\n",
    "\n",
    "![](https://miro.medium.com/max/1200/1*ba0XpZtJrgh7UpzWcIgZ1Q.jpeg)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_mat = PCA(np.array(train_df.iloc[:,0:1024].cov()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1024, 239)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "eig_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = np.matmul(np.array(train_df.iloc[:,:1024]),eig_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(78200, 239)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "reduced_data.shape"
   ]
  },
  {
   "source": [
    "Calculating class covariances for each class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_covarainces = list(map(lambda x : train_df[train_df['labels'] == x].iloc[:,:1024].cov() , unique_labels))"
   ]
  },
  {
   "source": [
    "## Applying RDA\n",
    "**RDA** : Regularized discriminant analysis uses the same general setup as LDA and QDA but estimates the covariance in a new way, which combines the covariance of QDA using (Σk) and with the covariance of LDA (Σ) using tuning parameter λ.\n",
    "\n",
    "$$ \\sigma_k(\\lambda) = (1 - \\lambda)\\sigma_k + \\lambda \\sigma $$\n",
    "\n",
    "\n",
    "$$\\sigma_k(\\lambda,\\gamma) = (1 - \\gamma) \\sigma_k(\\lambda) + \\gamma \\frac1p tr(\\sigma_k(\\lambda))I$$\n",
    "Both γ and λ can be thought of as mixing parameters, as they both take values between 0 and 1. For the four extremes of γ and λ, the covariance structure reduces to special cases:\n",
    "- (γ=0,λ=0): QDA - individual covariance for each group.\n",
    "- (γ=0,λ=1): LDA - a common covariance matrix.\n",
    "- (γ=1,λ=0): Conditional independent variables - similar to Naive Bayes, but variable variances within group (main diagonal elements) are all equal.\n",
    "- (γ=1,λ=1): Classification using euclidean distance - as in previous case, but variances are the same for all groups. Objects are assigned to group with nearest mean."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regularised_matrix = RDA(class_covarainces,train_df,train_folder,unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "np.linalg.det(regularised_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(78200, 239)"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "reduced_data.shape"
   ]
  },
  {
   "source": [
    "### Calculating class covariance and mean vector for each class so that we can use calculate to **Posterior Probability** so as to perform classification."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_cov_mats_reduced = []\n",
    "\n",
    "classes_cov_mats_reduced.extend(map(lambda x: np.cov(reduced_data[(1700*x):(1700*(x+1)),:],rowvar=False),unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mean_vecs = []\n",
    "\n",
    "class_mean_vecs.extend(map(lambda x: np.mean(reduced_data[1700*x:1700*(x+1),:],axis=0),np.arange(0,len(train_folder))))"
   ]
  },
  {
   "source": [
    "#### Applying RDA on reduced data obtained after applying PCA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_reduced_rda_matrices = RDA(classes_cov_mats_reduced,train_df,train_folder,unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_reduced_test_data = np.matmul(test_df.iloc[:,:1024],eig_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(13800, 239)"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "pca_reduced_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_classes = np.concatenate(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_classes = actual_classes.reshape(13800,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_probs = []\n",
    "\n",
    "post_probs.extend(map(lambda x: post_prob(class_mean_vecs[x],pca_reduced_rda_matrices[x],pca_reduced_test_data),np.arange(0,len(train_folder))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_probabilities = np.concatenate(post_probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(13800, 46)"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "posterior_probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(posterior_probabilities,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = predicted_classes.reshape(13800,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(13800, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "actual_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count = np.count_nonzero(np.equal(predicted_classes,actual_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12606"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "correct_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (correct_count/actual_classes.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "91.34782608695652"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "accuracy"
   ]
  }
 ]
}